{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pyarrow as pa\n",
    "import seaborn as sns\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "dir = Path(r\"S:\\Fackler_OSS_364376\\data\\IRB-364376-v1-230215\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'S:\\\\Fackler_OSS_364376\\\\data\\\\IRB-364376-v1-230215/EHR/ptsd_record.csv.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# read ptsd records\u001b[39;00m\n\u001b[1;32m      2\u001b[0m fp \u001b[39m=\u001b[39m \u001b[39mdir\u001b[39m\u001b[39m.\u001b[39mjoinpath(\u001b[39m'\u001b[39m\u001b[39mEHR\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mptsd_record.csv.gz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m ptsd_record \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(fp, compression\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m patients_ptsd \u001b[39m=\u001b[39m ptsd_record[\u001b[39m'\u001b[39m\u001b[39mpat_enc_csn_sid\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[1;32m      6\u001b[0m \u001b[39m# read flow table of patient EHR records\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmemory_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding_errors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:750\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[39mif\u001b[39;00m compression \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    747\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    748\u001b[0m         \u001b[39m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[1;32m    749\u001b[0m         \u001b[39m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m         handle \u001b[39m=\u001b[39m gzip\u001b[39m.\u001b[39mGzipFile(  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    751\u001b[0m             filename\u001b[39m=\u001b[39mhandle,\n\u001b[1;32m    752\u001b[0m             mode\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m    753\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcompression_args,\n\u001b[1;32m    754\u001b[0m         )\n\u001b[1;32m    755\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    756\u001b[0m         handle \u001b[39m=\u001b[39m gzip\u001b[39m.\u001b[39mGzipFile(\n\u001b[1;32m    757\u001b[0m             \u001b[39m# No overload variant of \"GzipFile\" matches argument types\u001b[39;00m\n\u001b[1;32m    758\u001b[0m             \u001b[39m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcompression_args,\n\u001b[1;32m    762\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/gzip.py:174\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    172\u001b[0m     mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    173\u001b[0m \u001b[39mif\u001b[39;00m fileobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     fileobj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmyfileobj \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, mode \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fileobj, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'S:\\\\Fackler_OSS_364376\\\\data\\\\IRB-364376-v1-230215/EHR/ptsd_record.csv.gz'"
     ]
    }
   ],
   "source": [
    "# read ptsd records\n",
    "fp = dir.joinpath('EHR', 'ptsd_record.csv.gz')\n",
    "ptsd_record = pd.read_csv(fp, compression=\"gzip\")\n",
    "patients_ptsd = ptsd_record['pat_enc_csn_sid'].unique()\n",
    "\n",
    "# read flow table of patient EHR records\n",
    "fp = dir.joinpath('EHR', 'flowsheet.csv.gz')\n",
    "data = pd.read_csv(fp, compression=\"gzip\")\n",
    "data = data.drop(columns = ['meas_comment', 'meas_template_id'])\n",
    "# Note: pandas took 50 seconds to load the table. Consider porting to PySpark RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = dir.joinpath('EHR', 'd_flo_measures.csv.gz')\n",
    "dict = pd.read_csv(fp, compression=\"gzip\")\n",
    "\n",
    "names = [\"State Behavioral Scale\",\n",
    "\"-3 Unresponsive\", \n",
    "\"-2 Responsive to noxious stimuli\", \n",
    "\"-1 Responsive to gentle touch or voice\",\n",
    "\"0 Awake and Able to calm\",\n",
    "\"+1 Restless and difficult to calm\",\n",
    "\"+2 Agitated\",\n",
    "\"State Behavioral Scale (SBS)\",\n",
    "\"Achieved Level of Sedation\",\n",
    "\"Sedation / Delirium\",\n",
    "\"Richmond Agitation - Sedation Scale\",\n",
    "\"Richmond agitation sedation scale\",\n",
    "\"Richmond Agitation Sedation Scale (RASS)\"]\n",
    "\n",
    "# dict[dict['disp_name'].isin(names)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25878, 5)\n",
      "581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# flow_meas_id for SBS and RASS\n",
    "fmid = [304080016, 304080017, 304080018, 304080019, 304080020, 304080021]\n",
    "\n",
    "sbs = data[data['meas_id'].isin(fmid)]\n",
    "print(sbs.shape)\n",
    "# 25878 entries\n",
    "\n",
    "# calculate sbs score from offset\n",
    "sbs['SBS'] = sbs['meas_id'] - 304080019\n",
    "sbs = sbs.drop(columns=['meas_value', 'meas_id'])\n",
    "sbs['recorded_time'] = pd.to_datetime(sbs['recorded_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "sbs_indiv = sbs.groupby('pat_enc_csn_sid')\n",
    "\n",
    "# Identify patients with SBS and waveform data\n",
    "patients_ehr = list(sbs_indiv.groups.keys())\n",
    "\n",
    "patients = set(patients_ehr) & set(patients_ptsd)\n",
    "print(len(patients))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inclusion Exclusion criteria round 1\n",
    "- patients on ventilator\n",
    "        - contains MEDIBUSVITALS file (from Drager ventilator)\n",
    "        - overlapping ventilator time in (vent_dur)\n",
    "        - \n",
    "- patient on beta blocker\n",
    "- patients on neuromuscular blockers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mechanical ventilators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "levels of ventilator support\n",
    "- 1: room air\n",
    "- 2: supplemental O2\n",
    "- 3: regular nasal cannula\n",
    "- 4: high-flow nasal cannula\n",
    "- 5: noninvasive positive pressure ventilation\n",
    "- 6: conventional mechanical ventilation\n",
    "- 7: high freq oscillation or jet ventilation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_vent(patients, verbose = True):\n",
    "    fp = dir.joinpath('EHR', 'vent_dur.csv.gz')\n",
    "    vent_record = pd.read_csv(fp, compression=\"gzip\")\n",
    "\n",
    "    mech_vent = [5, 6, 7]\n",
    "    vent_record = vent_record[vent_record['level'].isin(mech_vent)]\n",
    "\n",
    "    patient_on_vent = set(vent_record['pat_enc_csn_sid'])\n",
    "    filtered_patients = patients - patient_on_vent\n",
    "    if verbose:\n",
    "        print(f'{len(filtered_patients)} removed for mechanical ventilation \\n{len(patients)} patients in original list, {len(filtered_patients)} after filtering')\n",
    "\n",
    "    return filtered_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324 removed for mechanical ventilation \n",
      "581 patients in original list, 324 after filtering\n"
     ]
    }
   ],
   "source": [
    "p_no_vent = remove_vent(patients)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drug\n",
    "exclude neuromuscular and beta blockers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- medication dictionary: d_med\n",
    "- accm_med_admin\n",
    "- anes_dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = dir.joinpath('EHR', 'med_admin.csv.gz')\n",
    "# med_admin = pd.read_csv(fp, compression=\"gzip\")\n",
    "# print(med_admin.keys())\n",
    "# print(med_admin['pharm_classname'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_drugs(patients, verbose = True):\n",
    "    fp = dir.joinpath('EHR', 'med_admin.csv.gz')\n",
    "    med_admin = pd.read_csv(fp, compression=\"gzip\")\n",
    "\n",
    "    excl_drugs = ['NEUROMUSCULAR BLOCKING AGENTS', 'BETA-ADRENERGIC AGENTS', 'ALPHA/BETA-ADRENERGIC BLOCKING AGENTS', 'BETA-ADRENERGIC BLOCKING AGENTS']\n",
    "\n",
    "    med_admin_filter = med_admin[med_admin['pharm_classname'].isin(excl_drugs)]\n",
    "    # med_admin_filter['pharm_classname'].unique()\n",
    "    patients_med = set(med_admin_filter['pat_enc_csn_sid'])\n",
    "\n",
    "    filtered_patients = patients - patients_med\n",
    "    if verbose:\n",
    "        print(f'{len(patients_med)} removed for drugs \\n{len(patients)} patients in original list, {len(filtered_patients)} after filtering')\n",
    "\n",
    "    return filtered_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DtypeWarning: Columns (26,40) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 removed for drugs \n",
      "581 patients in original list, 415 after filtering\n"
     ]
    }
   ],
   "source": [
    "p_no_drugs = remove_drugs(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415\n"
     ]
    }
   ],
   "source": [
    "p_no_drugs = np.array(list(p_no_drugs))\n",
    "print(len(p_no_drugs))\n",
    "np.save('./DONOTPUSH/patients_wodrugs', p_no_drugs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inclusion Exclusion 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Committee meeting feedback: \n",
    "- Preserve ventilator patients since SBS designed for ventilated patients and this population most likely to have low SBS scores\n",
    "- Instead remove respiration rate from data since low discrimination power\n",
    "- Usually patients desaturate before crashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13a0a7db74dc931e95168a9b504eadd3f616dade2353cce14264b5d4e454dcfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
